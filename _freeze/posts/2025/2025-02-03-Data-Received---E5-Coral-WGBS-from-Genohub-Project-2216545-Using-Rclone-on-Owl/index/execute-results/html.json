{
  "hash": "0dbadc7e34475a3b8fdd529573977c72",
  "result": {
    "engine": "knitr",
    "markdown": "---\nauthor: Sam White\ntoc-title: Contents\ntoc-depth: 5\ntoc-location: left\ntitle: Data Received - E5 Coral WGBS from Genohub Project 2216545 Using Rclone on Owl\ndate: '2025-02-03'\ndraft: false\nengine: knitr\ncategories: \n  - \"2025\"\n  - \"E5\"\n  - \"coral\"\n  - \"WGBS\"\n  - \"BS-seq\"\n  - \"bisulfite sequencing\"\n  - \"Genohub\"\n  - \"2216545\"\n  - \"Data Received\"\n  - \"rclone\"\n---\n\n\n\n# INTRO\n\nWhole genome bisulfite sequencing (WGBS) data was received from Genohub for Project 2216545, as part of [urol-e5/deep-dive-expression](https://github.com/urol-e5/deep-dive-expression). Genohub provided Amazon AWS S3 credentials for downloading. Installation of the AWS command line interface (CLI) was a bit too involved to try to figure out on Owl (our Synology server), which might be BSD Linux? Instead, I installed and configured [rclone](https://rclone.org/) on Owl.\n\n# METHODS\n\n## Configuring Rclone\n\nInstallation was a breeze. SSH'd into and then used the following command provided on the [rclone Downloads page](https://rclone.org/downloads/):\n\n`sudo -v ; curl https://rclone.org/install.sh | sudo bash`\n\nI performed the initial configuration step using the credentials supplied by Genohub.\n\n- `rclone config`\n\nThen, I ran the list command to view the contents of the S3 bucket on AWS:\n\n`rclone ls remote:`\n\nHowever, this did _not_ work!\n\n```\n2025/02/03 12:57:43 NOTICE: Failed to ls: operation error S3: ListBuckets, https response error StatusCode: 403, RequestID: SH6FBZZSFZVEFBMG, HostID: <redacted>, api error AccessDenied: User: arn:aws:iam::<redacted>:user/remote is not authorized to perform: s3:ListAllMyBuckets because no identity-based policy allows the s3:ListAllMyBuckets action\n```\n\nAfter some sleuthing in the Genohub documentation for using the AWS CLI, I realized I needed to specify the S3 bucket. In order to specify an S3 bucket with rclone, you need to [create an rclone alias](https://rclone.org/alias/) - you cannot configure S3 to access a bucket directory.\n\nSo, I set up an alias with rclone:\n\n1. Run `rclone config`\n\n2. Specify `n) New remote`\n\n3. `name> genohub`\n\n4. Specify `alias` as storage type:\n\n    ```\n    Type of storage to configure.\n    Choose a number from below, or type in your own value\n\n    >alias\n    ```\n\n5. ```remote> remote:genohub_bucket``` \n\n::: {.callout-note}\nYou need to replace `<genohub_bucket>` with the actual bucket ID provided by Genohub.\n:::\n\n6. Save the configuration at the prompt.\n\nThen, you can actually access your data using the alias `genohub`:\n\n`rclone ls genohub:`\n\n# DATA\n\nAll files were downloaded to `owl:/volume1/web/nightingales/E5-coral-deep-dive-expression/genohub2216545` and MD5 checksums verified:\n\n::: {.callout-note}\nAn astute reader might notice that the screenshot below shows a different directory than that listed above. At the time of downloading, I wasn't sure which project this belonged to. I have since updated and moved the data to the correct directory.\n:::\n\n![Screenshot of MD5 checksum verifications.](./20250203-e5-wgbs-genohub-md5-verification-01.png)",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}